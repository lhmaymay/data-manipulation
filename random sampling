from sklearn.model_selection import train_test_split
import pandas as pd


#1:simple random sampling
sample_df=df.sample(1000)
sample_df=df.sample(frac=0.8)

#2:stratified sampling
X_train, X_test, y_train, y_test = train_test_split(diabetes.loc[:, diabetes.columns != 'class'], diabetes['class'], 
                                                      test_size=0.3, stratify=diabetes['class'], random_state=66)
                                                      
#3:Reservior sampling
#Say you have a stream of items of large and unknown length that we can only iterate over once.
#Create an algorithm that randomly chooses an item from this stream such that each item is equally likely to be selected.
#Reservoir sampling is super useful when there is an endless stream of data and your goal is to grab a small sample with uniform probability.
#Given a sample of size K with N items processed so far, the chance for any item to be selected is K/N. When the next item comes in, 
#current sample has a chance to survive K/N*N/(N+1)=K/(N+1) while the new item has chance K/(N+1) to be selected.


#4:Thompson sampling
